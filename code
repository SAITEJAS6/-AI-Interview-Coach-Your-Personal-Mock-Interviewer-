import cv2
import tkinter as tk
from tkinter import messagebox
import threading
import time
import numpy as np
import speech_recognition as sr

class InterviewCoach:
    def __init__(self, root):
        self.root = root
        self.root.title("üé§ AI Interview Coach")
        self.root.geometry("600x500")
        self.root.configure(bg="#222")
        
        self.is_recording = False
        self.cap = None
        self.face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
        
        self.title_label = tk.Label(root, text="AI Interview Coach", font=("Arial", 16, "bold"), fg="white", bg="#222")
        self.title_label.pack(pady=10)
        
        self.start_btn = tk.Button(root, text="üé§ Start Interview", font=("Arial", 14), bg="#28a745", fg="white", padx=20, pady=10, command=self.start_interview)
        self.start_btn.pack(pady=10)
        
        self.stop_btn = tk.Button(root, text="üõë Stop Interview", font=("Arial", 14), bg="#dc3545", fg="white", padx=20, pady=10, command=self.stop_interview, state=tk.DISABLED)
        self.stop_btn.pack(pady=10)
        
        self.feedback_label = tk.Label(root, text="", font=("Arial", 12), fg="white", bg="#222", wraplength=500, justify="center")
        self.feedback_label.pack(pady=20)
        
    def start_interview(self):
        self.feedback_label.config(text="Recording... Speak naturally! üéôÔ∏è", fg="yellow")
        self.is_recording = True
        self.start_btn.config(state=tk.DISABLED)
        self.stop_btn.config(state=tk.NORMAL)
        threading.Thread(target=self.record_video).start()
        threading.Thread(target=self.analyze_speech).start()
        
    def stop_interview(self):
        self.is_recording = False
        self.stop_btn.config(state=tk.DISABLED)
        self.start_btn.config(state=tk.NORMAL)
        self.feedback_label.config(text="Processing Feedback... ‚è≥", fg="yellow")
        time.sleep(2)
        feedback = self.generate_feedback()
        self.feedback_label.config(text=feedback, fg="cyan")
    
    def record_video(self):
        self.cap = cv2.VideoCapture(0)
        while self.is_recording:
            ret, frame = self.cap.read()
            if not ret:
                break
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, scaleFactor=1.3, minNeighbors=5)
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.imshow('Interview Recording', frame)
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        self.cap.release()
        cv2.destroyAllWindows()
        
    def analyze_speech(self):
        recognizer = sr.Recognizer()
        mic = sr.Microphone()
        with mic as source:
            recognizer.adjust_for_ambient_noise(source)
            while self.is_recording:
                try:
                    audio = recognizer.listen(source, timeout=5)
                    text = recognizer.recognize_google(audio)
                    print("You said:", text)
                except Exception as e:
                    print("Error in speech recognition:", e)
    
    def generate_feedback(self):
        feedbacks = [
            "‚úÖ Your facial expressions were confident!",
            "üé≠ Try to use more natural gestures.",
            "üó£Ô∏è Your voice was clear, but try varying tone for engagement.",
            "üôÇ Maintain eye contact with the camera for better presence.",
            "ü§î Avoid long pauses, stay confident while answering."
        ]
        return "\n".join(np.random.choice(feedbacks, 3, replace=False))
    
root = tk.Tk()
app = InterviewCoach(root)
root.mainloop()
